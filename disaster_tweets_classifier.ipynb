{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcfe116f-8b10-4002-88da-bc4cc247b550",
   "metadata": {},
   "source": [
    "## Experiment log:\n",
    "- First, we took only the tweet text, without keywords or locations, and tried a simple model with an embedding layer, followed by a mean layer, then the output layers. Stopwords were not removed and no stemming was performed. Accuracy was varying between runs, ranging between 0.625 0.96875. We can do better.\n",
    "- Next,we tried removing stopwords. Accuracy did not peak as high as it was before, but the variance was less. Acuracy ranged between 0.46875 and 0.8125.\n",
    "- We tried stemming alone. Same as removing stopwords. Acuracy ranged between 0.5 and 0.8125.\n",
    "- Both stemming and removing stopwords made the training smoother, with the accuracy less fluctuating and almost steadily increasing. Range was between 0.46875 and 0.75.\n",
    "- After looking at kewyords, they seem helpful. They are the one or few words that are the main focus of the tweet. We could use that.\n",
    "- We tried just appending the keywords at the end of the original tweets, althought they are there anyway. We thought that would help the model pay more attention to the keyword and that would help capturing the sentiment of the tweet. It could have done that, but we did not see any significant increase in accuracy, it was between 0.5 and 0.8125. We need to think of another way to include them.\n",
    "-  Next, we tried an Embedding, LSTM, Fn (select_last), Dense (output), LogSoftmax/Sigmoid/Relu architecture. It was terrible! The accuracy was 0.5 most of the time, and even dropped to 0.40625 briefly. \n",
    "- We tried then to be creative :D we created two branches of Embedding, Mean, Dense, and LogSoftmax, one to process the tweet text and the other to process the keyword alone, then we averaged the log-softmax scores. The results were much better! The accuracy peaked at 1.0 briefly. We then did some tweaking of the learning rate and number of iterations not just to get higher accuracy but also to make it more steady and consistent.\n",
    "- Locations seemed interesting, I tried looking up location values in a third party repository for geolocation data. We were particularly interested in longitude and latitude. I got that, converted long/lat to spherical coordinates, fed that to a third branch in the model, and averaged the scores. The results were terrible! The model accuracy struggled to stay between mid 50s and mid 40s. It even dropped below that range. I tried adding another hidden layer between the input and output layers in that branch but that did not help. The problem I could see is that there were multiple suggestions for so many locations. I tried choosing one at random and choosing the first one, but neither helped. Also, imputing missing location values with 0s for lon and lat could have made things worse, because that's an actual geographical location that the model tried to relate to disasters.\n",
    "- I tried reading location like I read text and keyword and using the vocabulary to transform it into a a tensor, and run it through yet another branch. Results were better that the geolcation data not really impressive.\n",
    "- Next thing to try was to concatenate keywords and locations to the text with separators in between, and use the original architecture with Embedding, Mean, Dense, and LogSoftmax layers. It worked. Average accuracy was 0.691\n",
    "- I really wanted to make this better, I added key word to location and fed it to a separate branch, and the tweet body to the other branch, we could squeeze a few more hundredths of degrees of accuracy and F1 scores, average accuracy was   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c6ff82-5cba-43ec-8f4a-3ed77459fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import shutil\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import json\n",
    "import http.client, urllib.parse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import trax.fastmath.numpy as np\n",
    "from trax import layers as tl\n",
    "from trax import optimizers\n",
    "from trax.supervised import training\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec378a-e2f1-444e-bfd2-b519cec20e87",
   "metadata": {},
   "source": [
    "## Loading tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9e9d5a-97d4-4d3d-a262-f0bbd9620e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_PCT = 0.2\n",
    "MODEL_DIR = './model'\n",
    "OUTPUT_DIR = './output'\n",
    "stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed961e8-4704-44ef-a7eb-ab409971ec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 07:49:27.157281: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1193514"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBED_FILE = '../../data/glove.twitter.27B.200d.txt'\n",
    "EMBED = {}\n",
    "with open(EMBED_FILE) as emf:\n",
    "    for line in emf:\n",
    "        tokens = line.split()\n",
    "        EMBED[tokens[0]] = np.array(tokens[1:], 'float32')\n",
    "        \n",
    "len(EMBED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e08e71-2878-47c3-b7b3-44ff071ef391",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_tweets = pd.read_csv('data/train.csv')\n",
    "all_test_tweets = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb931b3-10c0-4f66-b7da-e7466dcbdd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_tweets.loc[all_train_tweets.target == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74d9944-dabc-4d9b-9ae6-352f3d8decd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword location                          text  target\n",
       "15  23     NaN      NaN                What's up man?       0\n",
       "16  24     NaN      NaN                 I love fruits       0\n",
       "17  25     NaN      NaN              Summer is lovely       0\n",
       "18  26     NaN      NaN             My car is so fast       0\n",
       "19  28     NaN      NaN  What a goooooooaaaaaal!!!!!!       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_tweets.loc[all_train_tweets.target == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e796db1-9ce7-4d88-b9f1-0624fa3f09dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31                       Birmingham\n",
       "32    Est. September 2012 - Bristol\n",
       "33                           AFRICA\n",
       "34                 Philadelphia, PA\n",
       "35                       London, UK\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_tweets.location.loc[~all_train_tweets.location.isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5bf63e-6403-439a-b89d-6160a92dfaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities               45\n",
       "deluge                   42\n",
       "armageddon               42\n",
       "sinking                  41\n",
       "damage                   41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_tweets.keyword.loc[~all_train_tweets.keyword.isna()].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dfebd12-c55f-44b2-8163-24db2467acca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C ablaze',\n",
       " 'We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw ablaze',\n",
       " '#AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi ablaze',\n",
       " 'Crying out for more! Set me ablaze ablaze',\n",
       " 'On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N ablaze']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# That is how the tweets looked like when we tried appending the keywords\n",
    "(all_train_tweets.text + ' ' + all_train_tweets.keyword.fillna('')).loc[~all_train_tweets.keyword.isna()].to_list()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b83fbcd7-88a5-4c32-a925-c6db1acd9911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6771                          \n",
       "7571                  Glasgow \n",
       "1797      Melbourne, Australia\n",
       "2752                      News\n",
       "3757                       å_ \n",
       "                 ...          \n",
       "4165           å_: ?? ÌÑ ? : ?\n",
       "6834      å_å_Los Mina Cityã¢\n",
       "6989        å¡å¡Midwest Û¢Û¢\n",
       "7183         åÊ(?Û¢`?Û¢å«)??\n",
       "2419               åø\\_(?)_/åø\n",
       "Name: location, Length: 5080, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Location seems useful. Very messy, though.\n",
    "all_train_tweets.location.loc[~all_train_tweets.location.isna()].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f459df4-c39c-4256-b882-6a2b4ef68c91",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0247cf8-cac1-449a-a9a4-b8124fc6d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet, remove_stopwords=False, stem=False):\n",
    "    if tweet:\n",
    "        # Remove hyper-links\n",
    "        tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "        # Remove hashtags\n",
    "        tweet = re.sub(r'#', '', tweet)\n",
    "        # Remove stock market tickers\n",
    "        tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "        # Remove old style tweet text RT\n",
    "        tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "        # Tokenize tweet\n",
    "        tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "        tweet = [word for word in tokenizer.tokenize(tweet) if word not in string.punctuation]\n",
    "        if remove_stopwords:\n",
    "            tweet = [word for word in tweet if word not in stopwords_english]\n",
    "        if stem:\n",
    "            stemmer = PorterStemmer()\n",
    "            tweet = [stemmer.stem(word) for word in tweet]\n",
    "    else:\n",
    "        tweet = ['__NA__']\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd72b8f-74f5-4e69-bf1f-db2f7d00126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_location(loc):\n",
    "    if loc:\n",
    "        tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "        loc = [word for word in tokenizer.tokenize(loc) if word not in string.punctuation]\n",
    "    else:\n",
    "        loc = ['__NA__']\n",
    "\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5da42b17-c695-4664-a1bb-96b22924990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset_df):\n",
    "    dataset_df['text_clean'] = dataset_df.text.apply(process_tweet, args=(True, False))\n",
    "    dataset_df['keyword_clean'] = dataset_df.keyword.fillna('').apply(process_tweet, args=(True, False))\n",
    "    dataset_df['location_clean'] = dataset_df.location.fillna('').apply(process_location)\n",
    "    \n",
    "clean_dataset(all_train_tweets)\n",
    "clean_dataset(all_test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f95b006-b208-407c-92f4-82ab7fdb5549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00     0.0\n",
       "0.25     6.0\n",
       "0.50     9.0\n",
       "0.75    12.0\n",
       "1.00    26.0\n",
       "Name: text_clean, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The purpose of this is to show how long the sequences we are dealing with.\n",
    "# The longer the sequence, the tricker it is to capture the whole meaning of the tweet.\n",
    "all_train_tweets.text_clean.map(lambda t: len(t)).quantile([0.0, 0.25, .50, 0.75, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36c6101e-845e-43ca-8c71-0b710041f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building vocabulary\n",
    "def build_vocab(tweets):\n",
    "    vocab = {\n",
    "        '__PAD__': 0,\n",
    "        '__</e>__': 1,\n",
    "        '__UNK__': 2,\n",
    "        '__TXT__': 3,\n",
    "        '__KW__': 4,\n",
    "        '__LOC__': 5,\n",
    "    }\n",
    "    for tweet in tweets:\n",
    "        for word in tweet:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "# vocab = build_vocab(all_train_tweets.text_clean.to_list() + all_train_tweets.location_clean.to_list())\n",
    "\n",
    "# Tweet to tensor\n",
    "def tweet_to_tensor(tweet, vocab, prefix=None, suffix=None):\n",
    "    tweet = [vocab.get(token, vocab['__UNK__']) for token in tweet]\n",
    "    if prefix:\n",
    "        tweet = [vocab[prefix]] + tweet\n",
    "    if suffix:\n",
    "        tweet = tweet + [vocab[suffix]]\n",
    "\n",
    "    return tweet\n",
    "\n",
    "def prep_dataset(dataset_df, vocab):\n",
    "    dataset_df['text_clean'] = dataset_df.text_clean.apply(tweet_to_tensor, args=(vocab, '__TXT__'))\n",
    "    dataset_df['keyword_clean'] = dataset_df.keyword_clean.apply(tweet_to_tensor, args=(vocab, '__KW__'))\n",
    "    dataset_df['location_clean'] = dataset_df.location_clean.apply(tweet_to_tensor, args=(vocab, '__LOC__', '__</e>__'))\n",
    "    dataset_df['input_clean'] = dataset_df.keyword_clean + dataset_df.location_clean\n",
    "\n",
    "prep_dataset(all_train_tweets, vocab)\n",
    "prep_dataset(all_test_tweets, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bfbdc4e-d292-4569-9fdd-30dbcead0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation split\n",
    "all_pos_train = all_train_tweets.loc[all_train_tweets.target == 1]\n",
    "all_neg_train = all_train_tweets.loc[all_train_tweets.target == 0]\n",
    "\n",
    "pos_cut_idx = int(all_pos_train.shape[0] * (1 - VAL_PCT))\n",
    "pos_val = all_pos_train.iloc[pos_cut_idx:]\n",
    "pos_train = all_pos_train.iloc[:pos_cut_idx]\n",
    "\n",
    "neg_cut_idx = int(all_neg_train.shape[0] * (1 - VAL_PCT))\n",
    "neg_val = all_neg_train.iloc[neg_cut_idx:]\n",
    "neg_train = all_neg_train.iloc[:neg_cut_idx] \n",
    "\n",
    "all_train = pd.concat([pos_train, neg_train])\n",
    "all_val = pd.concat([pos_val, neg_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3c3ca1d-5020-4679-a33a-842bbbfe7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We tried different ways to train the models. Not all parameters are currently used\n",
    "def data_generator(text_pos, text_neg, keyword_pos, keyword_neg, loc_pos, loc_neg, batch_size, vocab, loop=False):\n",
    "    len_pos = len(text_pos)\n",
    "    len_neg = len(text_neg)\n",
    "    \n",
    "    pos_idx_lines =  list(range(len_pos))\n",
    "    neg_idx_lines = list(range(len_neg))\n",
    "    \n",
    "    pos_idx = 0\n",
    "    neg_idx = 0\n",
    "    \n",
    "    n_to_take = batch_size // 2\n",
    "    \n",
    "    random.shuffle(pos_idx_lines)\n",
    "    random.shuffle(neg_idx_lines)\n",
    "    \n",
    "    stop = False\n",
    "    \n",
    "    while not stop:\n",
    "        batch_text = []\n",
    "        batch_keyword = []\n",
    "        batch_loc = []\n",
    "        targets = []\n",
    "        max_len_text = 0\n",
    "        max_len_keyword = 0\n",
    "        max_len_loc = 0\n",
    "        for i in range(n_to_take):\n",
    "            if pos_idx >= len_pos or neg_idx >= len_neg:\n",
    "                if not loop:\n",
    "                    stop = True\n",
    "                    break\n",
    "                if pos_idx >= len_pos:\n",
    "                    pos_idx = 0\n",
    "                    random.shuffle(pos_idx_lines)\n",
    "                if neg_idx >= len_neg:\n",
    "                    neg_idx = 0\n",
    "                    random.shuffle(neg_idx_lines)\n",
    "                    \n",
    "            # Tweet body\n",
    "            pos_text = text_pos[pos_idx]\n",
    "            batch_text.append(pos_text)\n",
    "            if len(pos_text) > max_len_text:\n",
    "                max_len_text = len(pos_text)\n",
    "            targets.append(1)\n",
    "                \n",
    "            neg_text = text_neg[neg_idx]\n",
    "            batch_text.append(neg_text)\n",
    "            if len(neg_text) > max_len_text:\n",
    "                max_len_text = len(neg_text)\n",
    "            targets.append(0)\n",
    "            \n",
    "            # Keyword\n",
    "            if keyword_pos:\n",
    "                pos_keyword = keyword_pos[pos_idx]\n",
    "                batch_keyword.append(pos_keyword)\n",
    "                if len(pos_keyword) > max_len_keyword:\n",
    "                    max_len_keyword = len(pos_keyword)\n",
    "                    \n",
    "                neg_keyword = keyword_neg[neg_idx]\n",
    "                batch_keyword.append(neg_keyword)\n",
    "                if len(neg_keyword) > max_len_keyword:\n",
    "                    max_len_keyword = len(neg_keyword)\n",
    "            \n",
    "            # Location\n",
    "            if loc_pos:\n",
    "                pos_loc = loc_pos[pos_idx]\n",
    "                batch_loc.append(pos_loc)\n",
    "                if len(pos_loc) > max_len_loc:\n",
    "                    max_len_loc = len(pos_loc)\n",
    "\n",
    "                neg_loc = loc_neg[neg_idx]\n",
    "                batch_loc.append(neg_loc)\n",
    "                if len(neg_loc) > max_len_loc:\n",
    "                    max_len_loc = len(neg_loc)\n",
    "\n",
    "            pos_idx += 1\n",
    "            neg_idx += 1\n",
    "                \n",
    "        if stop:\n",
    "            break\n",
    "            \n",
    "        pos_idx += n_to_take\n",
    "        neg_idx += n_to_take\n",
    "        \n",
    "        # padding\n",
    "        for elem in batch_text:\n",
    "            elem += [vocab['__PAD__']] * (max_len_text - len(elem))\n",
    "        for elem in batch_keyword:\n",
    "            elem += [vocab['__PAD__']] * (max_len_keyword - len(elem))\n",
    "        for elem in batch_loc:\n",
    "            elem += [vocab['__PAD__']] * (max_len_loc - len(elem))\n",
    "            \n",
    "        # We do not use them here, but they are expected by Trax\n",
    "        example_weights = np.array([1] * (n_to_take * 2))\n",
    "            \n",
    "        ret_vals = (np.array(batch_text),)\n",
    "        if keyword_pos:\n",
    "            ret_vals += (np.array(batch_keyword),)\n",
    "        if loc_pos:\n",
    "            ret_vals += (np.array(batch_loc),)\n",
    "        yield ret_vals + (np.array(targets), example_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef5d729e-e7e4-41be-b2af-d66c80d8d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(batch_size, train_text_pos, train_text_neg, train_keyword_pos, train_keyword_neg, train_loc_pos, train_loc_neg, vocab):\n",
    "    return data_generator(\n",
    "        text_pos=train_text_pos,\n",
    "        text_neg=train_text_neg,\n",
    "        keyword_pos=train_keyword_pos,\n",
    "        keyword_neg=train_keyword_neg,\n",
    "        loc_pos=train_loc_pos,\n",
    "        loc_neg=train_loc_neg,\n",
    "        batch_size=batch_size,\n",
    "        vocab=vocab,\n",
    "        loop=True\n",
    "    )\n",
    "def val_generator(batch_size, val_text_pos, val_text_neg, val_keyword_pos, val_keyword_neg, val_loc_pos, val_loc_neg, vocab):\n",
    "    return data_generator(\n",
    "        text_pos=val_text_pos,\n",
    "        text_neg=val_text_neg,\n",
    "        keyword_pos=val_keyword_pos,\n",
    "        keyword_neg=val_keyword_neg,\n",
    "        loc_pos=val_loc_pos,\n",
    "        loc_neg=val_loc_neg,\n",
    "        batch_size=batch_size,\n",
    "        vocab=vocab,\n",
    "        loop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90e551fe-333c-4506-906a-34f4a876bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_eval_tasks(\n",
    "    train_text_pos, train_text_neg, train_keyword_pos, train_keyword_neg, train_loc_pos, train_loc_neg,\n",
    "    val_text_pos, val_text_neg, val_keyword_pos, val_keyword_neg, val_loc_pos, val_loc_neg,\n",
    "    batch_size, vocab\n",
    "):\n",
    "    train_task = training.TrainTask(\n",
    "        labeled_data=train_generator(\n",
    "            batch_size=batch_size,\n",
    "            train_text_pos=train_text_pos,\n",
    "            train_text_neg=train_text_neg,\n",
    "            train_keyword_pos=train_keyword_pos,\n",
    "            train_keyword_neg=train_keyword_neg,\n",
    "            train_loc_pos=train_loc_pos,\n",
    "            train_loc_neg=train_loc_neg,\n",
    "            vocab=vocab,\n",
    "        ),\n",
    "        loss_layer=tl.CrossEntropyLoss(),\n",
    "        optimizer=optimizers.Adam(0.001),\n",
    "        n_steps_per_checkpoint=10,\n",
    "    )\n",
    "    eval_task = training.EvalTask(\n",
    "        labeled_data=val_generator(\n",
    "            batch_size=batch_size,\n",
    "            val_text_pos=val_text_pos,\n",
    "            val_text_neg=val_text_neg,\n",
    "            val_keyword_pos=val_keyword_pos,\n",
    "            val_keyword_neg=val_keyword_neg,\n",
    "            val_loc_pos=val_loc_pos,\n",
    "            val_loc_neg=val_loc_neg,\n",
    "            vocab=vocab,\n",
    "        ),\n",
    "        metrics=[\n",
    "            tl.CrossEntropyLoss(),\n",
    "            tl.Accuracy(),\n",
    "            tl.MacroAveragedFScore(),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return train_task, eval_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4150149f-19c7-4471-be08-10191ca60986",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 \n",
    "train_task, eval_task = get_train_eval_tasks(\n",
    "    train_text_pos=pos_train.text_clean.to_list(),\n",
    "    train_text_neg=neg_train.text_clean.to_list(),\n",
    "    train_keyword_pos=pos_train.input_clean.to_list(),\n",
    "    train_keyword_neg=neg_train.input_clean.to_list(),\n",
    "    train_loc_pos=[],\n",
    "    train_loc_neg=[],\n",
    "    val_text_pos=pos_val.text_clean.to_list(),\n",
    "    val_text_neg=neg_val.text_clean.to_list(),\n",
    "    val_keyword_pos=pos_val.input_clean.to_list(),\n",
    "    val_keyword_neg=neg_val.input_clean.to_list(),\n",
    "    val_loc_pos=[],\n",
    "    val_loc_neg=[],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    vocab=vocab,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5aa0f-b626-4b6d-866f-030888d51b45",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a1f05a59-4b1a-4b23-b8b9-18ca91eba596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding dimension. Something to experiemnt with.\n",
    "EMBED_DIM_TEXT = 265\n",
    "EMBED_DIM_KW = 128\n",
    "\n",
    "def select_last(seq):\n",
    "    return seq[:,-1,:]\n",
    "    \n",
    "\n",
    "def calc_avg(text_score, keyword_score):\n",
    "    return (text_score + keyword_score) / 2\n",
    "\n",
    "\n",
    "def classifier(vocab_size, embedding_dim_text, embedding_dim_kw):\n",
    "    return tl.Serial(\n",
    "        tl.Parallel(\n",
    "            tl.Serial(\n",
    "                tl.Embedding(\n",
    "                    vocab_size=vocab_size,\n",
    "                    d_feature=embedding_dim_text,\n",
    "                ),\n",
    "                tl.Mean(axis=1),\n",
    "                tl.Dense(n_units=2),\n",
    "                tl.LogSoftmax(),\n",
    "            ),\n",
    "            tl.Serial(\n",
    "                tl.Embedding(\n",
    "                    vocab_size=vocab_size,\n",
    "                    d_feature=embedding_dim_kw,\n",
    "                ),\n",
    "                tl.Mean(axis=1),\n",
    "                tl.Dense(n_units=2),\n",
    "                tl.LogSoftmax(),\n",
    "            ),\n",
    "        ),\n",
    "        tl.Fn('avg_score', calc_avg),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "25593b9b-778c-4d11-89cd-bbd5b103f846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial_in2[\n",
       "  Parallel_in2_out2[\n",
       "    Serial[\n",
       "      Embedding_14271_265\n",
       "      Mean\n",
       "      Dense_2\n",
       "      LogSoftmax\n",
       "    ]\n",
       "    Serial[\n",
       "      Embedding_14271_128\n",
       "      Mean\n",
       "      Dense_2\n",
       "      LogSoftmax\n",
       "    ]\n",
       "  ]\n",
       "  avg_score_in2\n",
       "]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = classifier(len(vocab), EMBED_DIM_TEXT, EMBED_DIM_KW,)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4058fd9-8f80-4a55-9e4a-08502ecb63ce",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b46a90c6-8598-45d4-8477-bc0d703d0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_task, eval_task, n_steps, output_dir):\n",
    "    training_loop = training.Loop(\n",
    "        model=model,\n",
    "        tasks=train_task,\n",
    "        eval_tasks=eval_task,\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "    \n",
    "    training_loop.run(n_steps=n_steps)\n",
    "    \n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5cc14300-ae1b-499e-935d-6d987671c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the model directory, otherwise old checkpoints might fail to load and training would fail\n",
    "for filename in os.listdir(MODEL_DIR):\n",
    "    file_path = os.path.join(MODEL_DIR, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9ca4d017-41a2-411f-b2af-d422807aa2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 5609293\n",
      "Step      1: Ran 1 train steps in 2.35 secs\n",
      "Step      1: train    CrossEntropyLoss |  0.69660389\n",
      "Step      1: eval     CrossEntropyLoss |  0.69705200\n",
      "Step      1: eval             Accuracy |  0.46875000\n",
      "Step      1: eval  MacroAveragedFScore |  0.31914893\n",
      "\n",
      "Step     10: Ran 9 train steps in 1.86 secs\n",
      "Step     10: train    CrossEntropyLoss |  0.69361019\n",
      "Step     10: eval     CrossEntropyLoss |  0.69237006\n",
      "Step     10: eval             Accuracy |  0.50000000\n",
      "Step     10: eval  MacroAveragedFScore |  0.33333334\n",
      "\n",
      "Step     20: Ran 10 train steps in 1.99 secs\n",
      "Step     20: train    CrossEntropyLoss |  0.69350845\n",
      "Step     20: eval     CrossEntropyLoss |  0.68803698\n",
      "Step     20: eval             Accuracy |  0.50000000\n",
      "Step     20: eval  MacroAveragedFScore |  0.33333334\n",
      "\n",
      "Step     30: Ran 10 train steps in 2.07 secs\n",
      "Step     30: train    CrossEntropyLoss |  0.69303834\n",
      "Step     30: eval     CrossEntropyLoss |  0.69192314\n",
      "Step     30: eval             Accuracy |  0.59375000\n",
      "Step     30: eval  MacroAveragedFScore |  0.59014785\n",
      "\n",
      "Step     40: Ran 10 train steps in 2.10 secs\n",
      "Step     40: train    CrossEntropyLoss |  0.69299734\n",
      "Step     40: eval     CrossEntropyLoss |  0.69286454\n",
      "Step     40: eval             Accuracy |  0.50000000\n",
      "Step     40: eval  MacroAveragedFScore |  0.33333334\n",
      "\n",
      "Step     50: Ran 10 train steps in 2.18 secs\n",
      "Step     50: train    CrossEntropyLoss |  0.68566424\n",
      "Step     50: eval     CrossEntropyLoss |  0.68351877\n",
      "Step     50: eval             Accuracy |  0.53125000\n",
      "Step     50: eval  MacroAveragedFScore |  0.43859649\n",
      "\n",
      "Step     60: Ran 10 train steps in 2.94 secs\n",
      "Step     60: train    CrossEntropyLoss |  0.68705165\n",
      "Step     60: eval     CrossEntropyLoss |  0.68408960\n",
      "Step     60: eval             Accuracy |  0.65625000\n",
      "Step     60: eval  MacroAveragedFScore |  0.63897437\n",
      "\n",
      "Step     70: Ran 10 train steps in 2.22 secs\n",
      "Step     70: train    CrossEntropyLoss |  0.68582654\n",
      "Step     70: eval     CrossEntropyLoss |  0.67892456\n",
      "Step     70: eval             Accuracy |  0.81250000\n",
      "Step     70: eval  MacroAveragedFScore |  0.80952382\n",
      "\n",
      "Step     80: Ran 10 train steps in 2.33 secs\n",
      "Step     80: train    CrossEntropyLoss |  0.68774790\n",
      "Step     80: eval     CrossEntropyLoss |  0.69037843\n",
      "Step     80: eval             Accuracy |  0.53125000\n",
      "Step     80: eval  MacroAveragedFScore |  0.49098623\n",
      "\n",
      "Step     90: Ran 10 train steps in 2.24 secs\n",
      "Step     90: train    CrossEntropyLoss |  0.68022525\n",
      "Step     90: eval     CrossEntropyLoss |  0.68547380\n",
      "Step     90: eval             Accuracy |  0.67187500\n",
      "Step     90: eval  MacroAveragedFScore |  0.66986001\n",
      "\n",
      "Step    100: Ran 10 train steps in 2.32 secs\n",
      "Step    100: train    CrossEntropyLoss |  0.67848343\n",
      "Step    100: eval     CrossEntropyLoss |  0.68390423\n",
      "Step    100: eval             Accuracy |  0.65625000\n",
      "Step    100: eval  MacroAveragedFScore |  0.63333333\n",
      "\n",
      "Step    110: Ran 10 train steps in 2.27 secs\n",
      "Step    110: train    CrossEntropyLoss |  0.67851436\n",
      "Step    110: eval     CrossEntropyLoss |  0.67986310\n",
      "Step    110: eval             Accuracy |  0.67187500\n",
      "Step    110: eval  MacroAveragedFScore |  0.66790223\n",
      "\n",
      "Step    120: Ran 10 train steps in 3.27 secs\n",
      "Step    120: train    CrossEntropyLoss |  0.67477471\n",
      "Step    120: eval     CrossEntropyLoss |  0.65798569\n",
      "Step    120: eval             Accuracy |  0.90625000\n",
      "Step    120: eval  MacroAveragedFScore |  0.90625000\n",
      "\n",
      "Step    130: Ran 10 train steps in 4.46 secs\n",
      "Step    130: train    CrossEntropyLoss |  0.66802245\n",
      "Step    130: eval     CrossEntropyLoss |  0.67551696\n",
      "Step    130: eval             Accuracy |  0.68750000\n",
      "Step    130: eval  MacroAveragedFScore |  0.67611337\n",
      "\n",
      "Step    140: Ran 10 train steps in 2.37 secs\n",
      "Step    140: train    CrossEntropyLoss |  0.66777432\n",
      "Step    140: eval     CrossEntropyLoss |  0.68010193\n",
      "Step    140: eval             Accuracy |  0.67187500\n",
      "Step    140: eval  MacroAveragedFScore |  0.66790223\n",
      "\n",
      "Step    150: Ran 10 train steps in 2.30 secs\n",
      "Step    150: train    CrossEntropyLoss |  0.66197640\n",
      "Step    150: eval     CrossEntropyLoss |  0.66068614\n",
      "Step    150: eval             Accuracy |  0.71875000\n",
      "Step    150: eval  MacroAveragedFScore |  0.71847510\n",
      "\n",
      "Step    160: Ran 10 train steps in 2.33 secs\n",
      "Step    160: train    CrossEntropyLoss |  0.65749198\n",
      "Step    160: eval     CrossEntropyLoss |  0.67425662\n",
      "Step    160: eval             Accuracy |  0.60937500\n",
      "Step    160: eval  MacroAveragedFScore |  0.56224346\n",
      "\n",
      "Step    170: Ran 10 train steps in 2.86 secs\n",
      "Step    170: train    CrossEntropyLoss |  0.65489292\n",
      "Step    170: eval     CrossEntropyLoss |  0.66099215\n",
      "Step    170: eval             Accuracy |  0.81250000\n",
      "Step    170: eval  MacroAveragedFScore |  0.80780780\n",
      "\n",
      "Step    180: Ran 10 train steps in 2.97 secs\n",
      "Step    180: train    CrossEntropyLoss |  0.64635909\n",
      "Step    180: eval     CrossEntropyLoss |  0.69445407\n",
      "Step    180: eval             Accuracy |  0.56250000\n",
      "Step    180: eval  MacroAveragedFScore |  0.55555558\n",
      "\n",
      "Step    190: Ran 10 train steps in 2.36 secs\n",
      "Step    190: train    CrossEntropyLoss |  0.65740913\n",
      "Step    190: eval     CrossEntropyLoss |  0.64544570\n",
      "Step    190: eval             Accuracy |  0.78125000\n",
      "Step    190: eval  MacroAveragedFScore |  0.78039217\n",
      "\n",
      "Step    200: Ran 10 train steps in 2.35 secs\n",
      "Step    200: train    CrossEntropyLoss |  0.64455527\n",
      "Step    200: eval     CrossEntropyLoss |  0.65931249\n",
      "Step    200: eval             Accuracy |  0.68750000\n",
      "Step    200: eval  MacroAveragedFScore |  0.68719453\n",
      "\n",
      "Step    210: Ran 10 train steps in 2.37 secs\n",
      "Step    210: train    CrossEntropyLoss |  0.63010365\n",
      "Step    210: eval     CrossEntropyLoss |  0.63162112\n",
      "Step    210: eval             Accuracy |  0.82812500\n",
      "Step    210: eval  MacroAveragedFScore |  0.82604396\n",
      "\n",
      "Step    220: Ran 10 train steps in 2.40 secs\n",
      "Step    220: train    CrossEntropyLoss |  0.62329495\n",
      "Step    220: eval     CrossEntropyLoss |  0.63089812\n",
      "Step    220: eval             Accuracy |  0.82812500\n",
      "Step    220: eval  MacroAveragedFScore |  0.82289308\n",
      "\n",
      "Step    230: Ran 10 train steps in 3.10 secs\n",
      "Step    230: train    CrossEntropyLoss |  0.62637258\n",
      "Step    230: eval     CrossEntropyLoss |  0.64988750\n",
      "Step    230: eval             Accuracy |  0.65625000\n",
      "Step    230: eval  MacroAveragedFScore |  0.64764762\n",
      "\n",
      "Step    240: Ran 10 train steps in 2.77 secs\n",
      "Step    240: train    CrossEntropyLoss |  0.62189090\n",
      "Step    240: eval     CrossEntropyLoss |  0.65011013\n",
      "Step    240: eval             Accuracy |  0.62500000\n",
      "Step    240: eval  MacroAveragedFScore |  0.61561561\n",
      "\n",
      "Step    250: Ran 10 train steps in 2.35 secs\n",
      "Step    250: train    CrossEntropyLoss |  0.61099339\n",
      "Step    250: eval     CrossEntropyLoss |  0.60792005\n",
      "Step    250: eval             Accuracy |  0.76562500\n",
      "Step    250: eval  MacroAveragedFScore |  0.76278722\n",
      "\n",
      "Step    260: Ran 10 train steps in 2.35 secs\n",
      "Step    260: train    CrossEntropyLoss |  0.58981133\n",
      "Step    260: eval     CrossEntropyLoss |  0.64857143\n",
      "Step    260: eval             Accuracy |  0.67187500\n",
      "Step    260: eval  MacroAveragedFScore |  0.64016068\n",
      "\n",
      "Step    270: Ran 10 train steps in 2.36 secs\n",
      "Step    270: train    CrossEntropyLoss |  0.59349865\n",
      "Step    270: eval     CrossEntropyLoss |  0.61365134\n",
      "Step    270: eval             Accuracy |  0.84375000\n",
      "Step    270: eval  MacroAveragedFScore |  0.84313726\n",
      "\n",
      "Step    280: Ran 10 train steps in 2.38 secs\n",
      "Step    280: train    CrossEntropyLoss |  0.59350109\n",
      "Step    280: eval     CrossEntropyLoss |  0.67378193\n",
      "Step    280: eval             Accuracy |  0.62500000\n",
      "Step    280: eval  MacroAveragedFScore |  0.62167484\n",
      "\n",
      "Step    290: Ran 10 train steps in 2.96 secs\n",
      "Step    290: train    CrossEntropyLoss |  0.58900768\n",
      "Step    290: eval     CrossEntropyLoss |  0.60844523\n",
      "Step    290: eval             Accuracy |  0.73437500\n",
      "Step    290: eval  MacroAveragedFScore |  0.73379004\n",
      "\n",
      "Step    300: Ran 10 train steps in 4.87 secs\n",
      "Step    300: train    CrossEntropyLoss |  0.57681406\n",
      "Step    300: eval     CrossEntropyLoss |  0.56511754\n",
      "Step    300: eval             Accuracy |  0.85937500\n",
      "Step    300: eval  MacroAveragedFScore |  0.85934067\n",
      "\n",
      "Step    310: Ran 10 train steps in 2.39 secs\n",
      "Step    310: train    CrossEntropyLoss |  0.57895076\n",
      "Step    310: eval     CrossEntropyLoss |  0.60570586\n",
      "Step    310: eval             Accuracy |  0.78125000\n",
      "Step    310: eval  MacroAveragedFScore |  0.77777779\n",
      "\n",
      "Step    320: Ran 10 train steps in 2.37 secs\n",
      "Step    320: train    CrossEntropyLoss |  0.55694044\n",
      "Step    320: eval     CrossEntropyLoss |  0.66821271\n",
      "Step    320: eval             Accuracy |  0.64062500\n",
      "Step    320: eval  MacroAveragedFScore |  0.63627380\n",
      "\n",
      "Step    330: Ran 10 train steps in 2.37 secs\n",
      "Step    330: train    CrossEntropyLoss |  0.56417274\n",
      "Step    330: eval     CrossEntropyLoss |  0.58774668\n",
      "Step    330: eval             Accuracy |  0.81250000\n",
      "Step    330: eval  MacroAveragedFScore |  0.81176472\n",
      "\n",
      "Step    340: Ran 10 train steps in 2.40 secs\n",
      "Step    340: train    CrossEntropyLoss |  0.53312188\n",
      "Step    340: eval     CrossEntropyLoss |  0.62786734\n",
      "Step    340: eval             Accuracy |  0.68750000\n",
      "Step    340: eval  MacroAveragedFScore |  0.68627453\n",
      "\n",
      "Step    350: Ran 10 train steps in 3.10 secs\n",
      "Step    350: train    CrossEntropyLoss |  0.55686510\n",
      "Step    350: eval     CrossEntropyLoss |  0.59560233\n",
      "Step    350: eval             Accuracy |  0.79687500\n",
      "Step    350: eval  MacroAveragedFScore |  0.79277706\n",
      "\n",
      "Step    360: Ran 10 train steps in 2.35 secs\n",
      "Step    360: train    CrossEntropyLoss |  0.55212593\n",
      "Step    360: eval     CrossEntropyLoss |  0.59238458\n",
      "Step    360: eval             Accuracy |  0.76562500\n",
      "Step    360: eval  MacroAveragedFScore |  0.76556778\n",
      "\n",
      "Step    370: Ran 10 train steps in 2.32 secs\n",
      "Step    370: train    CrossEntropyLoss |  0.52660930\n",
      "Step    370: eval     CrossEntropyLoss |  0.61191380\n",
      "Step    370: eval             Accuracy |  0.76562500\n",
      "Step    370: eval  MacroAveragedFScore |  0.76418567\n",
      "\n",
      "Step    380: Ran 10 train steps in 2.43 secs\n",
      "Step    380: train    CrossEntropyLoss |  0.50091529\n",
      "Step    380: eval     CrossEntropyLoss |  0.58626723\n",
      "Step    380: eval             Accuracy |  0.79687500\n",
      "Step    380: eval  MacroAveragedFScore |  0.79682547\n",
      "\n",
      "Step    390: Ran 10 train steps in 2.33 secs\n",
      "Step    390: train    CrossEntropyLoss |  0.52504981\n",
      "Step    390: eval     CrossEntropyLoss |  0.65960395\n",
      "Step    390: eval             Accuracy |  0.64062500\n",
      "Step    390: eval  MacroAveragedFScore |  0.63841808\n",
      "\n",
      "Step    400: Ran 10 train steps in 2.71 secs\n",
      "Step    400: train    CrossEntropyLoss |  0.53165090\n",
      "Step    400: eval     CrossEntropyLoss |  0.53050798\n",
      "Step    400: eval             Accuracy |  0.89062500\n",
      "Step    400: eval  MacroAveragedFScore |  0.88995337\n",
      "\n",
      "Step    410: Ran 10 train steps in 2.90 secs\n",
      "Step    410: train    CrossEntropyLoss |  0.52750313\n",
      "Step    410: eval     CrossEntropyLoss |  0.55171204\n",
      "Step    410: eval             Accuracy |  0.78125000\n",
      "Step    410: eval  MacroAveragedFScore |  0.78039217\n",
      "\n",
      "Step    420: Ran 10 train steps in 2.46 secs\n",
      "Step    420: train    CrossEntropyLoss |  0.49400339\n",
      "Step    420: eval     CrossEntropyLoss |  0.62995017\n",
      "Step    420: eval             Accuracy |  0.70312500\n",
      "Step    420: eval  MacroAveragedFScore |  0.70247126\n",
      "\n",
      "Step    430: Ran 10 train steps in 2.37 secs\n",
      "Step    430: train    CrossEntropyLoss |  0.47739944\n",
      "Step    430: eval     CrossEntropyLoss |  0.55154681\n",
      "Step    430: eval             Accuracy |  0.76562500\n",
      "Step    430: eval  MacroAveragedFScore |  0.75553858\n",
      "\n",
      "Step    440: Ran 10 train steps in 2.36 secs\n",
      "Step    440: train    CrossEntropyLoss |  0.51169407\n",
      "Step    440: eval     CrossEntropyLoss |  0.58772349\n",
      "Step    440: eval             Accuracy |  0.79687500\n",
      "Step    440: eval  MacroAveragedFScore |  0.79682547\n",
      "\n",
      "Step    450: Ran 10 train steps in 2.32 secs\n",
      "Step    450: train    CrossEntropyLoss |  0.48892468\n",
      "Step    450: eval     CrossEntropyLoss |  0.63355905\n",
      "Step    450: eval             Accuracy |  0.67187500\n",
      "Step    450: eval  MacroAveragedFScore |  0.67115247\n",
      "\n",
      "Step    460: Ran 10 train steps in 3.17 secs\n",
      "Step    460: train    CrossEntropyLoss |  0.47465944\n",
      "Step    460: eval     CrossEntropyLoss |  0.65953809\n",
      "Step    460: eval             Accuracy |  0.70312500\n",
      "Step    460: eval  MacroAveragedFScore |  0.70247126\n",
      "\n",
      "Step    470: Ran 10 train steps in 4.77 secs\n",
      "Step    470: train    CrossEntropyLoss |  0.47916049\n",
      "Step    470: eval     CrossEntropyLoss |  0.71975666\n",
      "Step    470: eval             Accuracy |  0.64062500\n",
      "Step    470: eval  MacroAveragedFScore |  0.63627380\n",
      "\n",
      "Step    480: Ran 10 train steps in 2.87 secs\n",
      "Step    480: train    CrossEntropyLoss |  0.47761807\n",
      "Step    480: eval     CrossEntropyLoss |  0.58839118\n",
      "Step    480: eval             Accuracy |  0.73437500\n",
      "Step    480: eval  MacroAveragedFScore |  0.71893567\n",
      "\n",
      "Step    490: Ran 10 train steps in 2.33 secs\n",
      "Step    490: train    CrossEntropyLoss |  0.46066952\n",
      "Step    490: eval     CrossEntropyLoss |  0.63348544\n",
      "Step    490: eval             Accuracy |  0.73437500\n",
      "Step    490: eval  MacroAveragedFScore |  0.72628927\n",
      "\n",
      "Step    500: Ran 10 train steps in 2.35 secs\n",
      "Step    500: train    CrossEntropyLoss |  0.44661683\n",
      "Step    500: eval     CrossEntropyLoss |  0.52183104\n",
      "Step    500: eval             Accuracy |  0.89062500\n",
      "Step    500: eval  MacroAveragedFScore |  0.89059830\n"
     ]
    }
   ],
   "source": [
    "training_loop = train_model(\n",
    "    model=model,\n",
    "    train_task=train_task,\n",
    "    eval_task=[eval_task],\n",
    "    n_steps=500,\n",
    "    output_dir=MODEL_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d85256d5-73cc-4c9a-ae0c-8acff9c05f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Average F1 0.6849855885786169\n",
      ">>> Average Accuracy 0.7052696078431373\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_acc = training_loop.history.to_dict()['_values']['eval']['metrics/Accuracy']\n",
    "hist_f1 = training_loop.history.to_dict()['_values']['eval']['metrics/MacroAveragedFScore']\n",
    "steps = [t[0] for t in hist_f1]\n",
    "vals_f1 = [t[1] for t in hist_f1]\n",
    "vals_acc = [t[1] for t in hist_acc]\n",
    "import statistics as st\n",
    "avg_f1 = st.mean(vals_f1)\n",
    "avg_acc = st.mean(vals_acc)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.plot(steps, vals_f1);\n",
    "ax.plot(steps, [avg_f1] * len(vals_f1), linestyle=\"-.\")\n",
    "ax.plot(steps, [avg_acc] * len(vals_acc), linestyle=\":\")\n",
    "print(f'>>> Average F1 {avg_f1}')\n",
    "print(f'>>> Average Accuracy {avg_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b9512-af8f-4d81-b222-e9e7d7a33d19",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9457493-9b27-4bf2-8905-68904c4bbb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atom/work/nlp/nlpenv/lib/python3.8/site-packages/jax/_src/lax/lax.py:4503: DeprecationWarning: Converting `np.integer` or `np.signedinteger` to a dtype is deprecated. The current result is `np.dtype(np.int_)` which is not strictly correct. Note that the result depends on the system. To ensure stable results use may want to use `np.int64` or `np.int32`.\n",
      "  np_dtype = np.dtype(dtype)\n",
      "/home/atom/work/nlp/nlpenv/lib/python3.8/site-packages/jax/_src/dtypes.py:62: DeprecationWarning: Converting `np.integer` or `np.signedinteger` to a dtype is deprecated. The current result is `np.dtype(np.int_)` which is not strictly correct. Note that the result depends on the system. To ensure stable results use may want to use `np.int64` or `np.int32`.\n",
      "  dtype = np.dtype(dtype)\n",
      "/home/atom/work/nlp/nlpenv/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:4459: UserWarning: Explicitly requested dtype <class 'numpy.integer'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax_internal._check_user_dtype_supported(dtype, \"astype\")\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "max_len_text = all_test_tweets.text_clean.map(len).max().item()\n",
    "max_len_in = all_test_tweets.input_clean.map(len).max().item()\n",
    "\n",
    "def pad(tweet, max_len):\n",
    "    return tweet + ([0] * (max_len - len(tweet)))\n",
    "\n",
    "all_test_tweets['text_clean'] = all_test_tweets.text_clean.apply(pad, args=(max_len_text,))\n",
    "all_test_tweets['input_clean'] = all_test_tweets.input_clean.apply(pad, args=(max_len_in,))\n",
    "\n",
    "preds = training_loop.eval_model((np.array(all_test_tweets.text_clean.to_list()), np.array(all_test_tweets.input_clean.to_list())))\n",
    "target = np.array([pred[1] > pred[0] for pred in preds]).astype(np.integer)\n",
    "all_test_tweets['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d161d715-d548-4d53-8ea6-744766986621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "all_test_tweets[['id', 'target']].to_csv(f'{OUTPUT_DIR}/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ee66474-fe13-4ef7-b798-eb28d320ae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Embedding in module trax.layers.core:\n",
      "\n",
      "class Embedding(trax.layers.base.Layer)\n",
      " |  Embedding(vocab_size, d_feature, use_bfloat16=False, kernel_initializer=<function ScaledInitializer.<locals>.Init at 0x7efc94333d30>)\n",
      " |  \n",
      " |  Trainable layer that maps discrete tokens/IDs to vectors.\n",
      " |  \n",
      " |  Embedding layers are commonly used to map discrete data, like words in NLP,\n",
      " |  into vectors. Here is a canonical example::\n",
      " |  \n",
      " |      vocab_size = 5\n",
      " |      word_ids = np.array([1, 2, 3, 4], dtype=np.int32)  # word_ids < vocab_size\n",
      " |      embedding_layer = tl.Embedding(vocab_size, 32)\n",
      " |      embedding_layer.init(trax.shapes.signature(word_ids))\n",
      " |      embedded = embedding_layer(word_ids)  # embedded.shape = (4, 32)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Embedding\n",
      " |      trax.layers.base.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, vocab_size, d_feature, use_bfloat16=False, kernel_initializer=<function ScaledInitializer.<locals>.Init at 0x7efc94333d30>)\n",
      " |      Returns an embedding layer with given vocabulary size and vector size.\n",
      " |      \n",
      " |      The layer clips input values (token IDs) to the range `[0, vocab_size)`.\n",
      " |      That is, negative token IDs all clip to `0` before being mapped to a\n",
      " |      vector, and token IDs with value `vocab_size` or greater all clip to\n",
      " |      `vocab_size - 1` before being mapped to a vector.\n",
      " |      \n",
      " |      Args:\n",
      " |        vocab_size: Size of the input vocabulary. The layer will assign a unique\n",
      " |          vector to each id in `range(vocab_size)`.\n",
      " |        d_feature: Dimensionality/depth of the output vectors.\n",
      " |        use_bfloat16: If `True`, use bfloat16 weights instead of the default\n",
      " |          float32; this can save memory but may (rarely) lead to numerical issues.\n",
      " |        kernel_initializer: Function that creates (random) initial vectors for\n",
      " |          the embedding.\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      Returns embedding vectors corresponding to input token IDs.\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Tensor of token IDs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Tensor of embedding vectors.\n",
      " |  \n",
      " |  init_weights_and_state(self, input_signature)\n",
      " |      Randomly initializes this layer's weights.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  __call__(self, x, weights=None, state=None, rng=None)\n",
      " |      Makes layers callable; for use in tests or interactive settings.\n",
      " |      \n",
      " |      This convenience method helps library users play with, test, or otherwise\n",
      " |      probe the behavior of layers outside of a full training environment. It\n",
      " |      presents the layer as callable function from inputs to outputs, with the\n",
      " |      option of manually specifying weights and non-parameter state per individual\n",
      " |      call. For convenience, weights and non-parameter state are cached per layer\n",
      " |      instance, starting from default values of `EMPTY_WEIGHTS` and `EMPTY_STATE`,\n",
      " |      and acquiring non-empty values either by initialization or from values\n",
      " |      explicitly provided via the weights and state keyword arguments, in which\n",
      " |      case the old weights will be preserved, and the state will be updated.\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Zero or more input tensors, packaged as described in the `Layer` class\n",
      " |            docstring.\n",
      " |        weights: Weights or `None`; if `None`, use self's cached weights value.\n",
      " |        state: State or `None`; if `None`, use self's cached state value.\n",
      " |        rng: Single-use random number generator (JAX PRNG key), or `None`;\n",
      " |            if `None`, use a default computed from an integer 0 seed.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Zero or more output tensors, packaged as described in the `Layer` class\n",
      " |        docstring.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Renders this layer as a medium-detailed string, to help in debugging.\n",
      " |      \n",
      " |      Subclasses should aim for high-signal/low-noise when overriding this\n",
      " |      method.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A high signal-to-noise string representing this layer.\n",
      " |  \n",
      " |  __setattr__(self, attr, value)\n",
      " |      Sets class attributes and protects from typos.\n",
      " |      \n",
      " |      In Trax layers, we only allow to set the following public attributes::\n",
      " |      \n",
      " |        - weights\n",
      " |        - state\n",
      " |        - rng\n",
      " |      \n",
      " |      This function prevents from setting other public attributes to avoid typos,\n",
      " |      for example, this is not possible and would be without this function::\n",
      " |      \n",
      " |        [typo]   layer.weighs = some_tensor\n",
      " |      \n",
      " |      If you need to set other public attributes in a derived class (which we\n",
      " |      do not recommend as in almost all cases it suffices to use a private\n",
      " |      attribute), override self._settable_attrs to include the attribute name.\n",
      " |      \n",
      " |      Args:\n",
      " |        attr: Name of the attribute to be set.\n",
      " |        value: Value to be assigned to the attribute.\n",
      " |  \n",
      " |  backward(self, inputs, output, grad, weights, state, new_state, rng)\n",
      " |      Custom backward pass to propagate gradients in a custom way.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensors; can be a (possibly nested) tuple.\n",
      " |        output: The result of running this layer on inputs.\n",
      " |        grad: Gradient signal computed based on subsequent layers; its structure\n",
      " |            and shape must match output.\n",
      " |        weights: This layer's weights.\n",
      " |        state: This layer's state prior to the current forward pass.\n",
      " |        new_state: This layer's state after the current forward pass.\n",
      " |        rng: Single-use random number generator (JAX PRNG key).\n",
      " |      \n",
      " |      Returns:\n",
      " |        The custom gradient signal for the input. Note that we need to return\n",
      " |        a gradient for each argument of forward, so it will usually be a tuple\n",
      " |        of signals: the gradient for inputs and weights.\n",
      " |  \n",
      " |  init(self, input_signature, rng=None, use_cache=False)\n",
      " |      Initializes weights/state of this layer and its sublayers recursively.\n",
      " |      \n",
      " |      Initialization creates layer weights and state, for layers that use them.\n",
      " |      It derives the necessary array shapes and data types from the layer's input\n",
      " |      signature, which is itself just shape and data type information.\n",
      " |      \n",
      " |      For layers without weights or state, this method safely does nothing.\n",
      " |      \n",
      " |      This method is designed to create weights/state only once for each layer\n",
      " |      instance, even if the same layer instance occurs in multiple places in the\n",
      " |      network. This enables weight sharing to be implemented as layer sharing.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: `ShapeDtype` instance (if this layer takes one input)\n",
      " |            or list/tuple of `ShapeDtype` instances.\n",
      " |        rng: Single-use random number generator (JAX PRNG key), or `None`;\n",
      " |            if `None`, use a default computed from an integer 0 seed.\n",
      " |        use_cache: If `True`, and if this layer instance has already been\n",
      " |            initialized elsewhere in the network, then return special marker\n",
      " |            values -- tuple `(GET_WEIGHTS_FROM_CACHE, GET_STATE_FROM_CACHE)`.\n",
      " |            Else return this layer's newly initialized weights and state.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `(weights, state)` tuple.\n",
      " |  \n",
      " |  init_from_file(self, file_name, weights_only=False, input_signature=None)\n",
      " |      Initializes this layer and its sublayers from a pickled checkpoint.\n",
      " |      \n",
      " |      In the common case (`weights_only=False`), the file must be a gziped pickled\n",
      " |      dictionary containing items with keys `'flat_weights', `'flat_state'` and\n",
      " |      `'input_signature'`, which are used to initialize this layer.\n",
      " |      If `input_signature` is specified, it's used instead of the one in the file.\n",
      " |      If `weights_only` is `True`, the dictionary does not need to have the\n",
      " |      `'flat_state'` item and the state it not restored either.\n",
      " |      \n",
      " |      Args:\n",
      " |        file_name: Name/path of the pickled weights/state file.\n",
      " |        weights_only: If `True`, initialize only the layer's weights. Else\n",
      " |            initialize both weights and state.\n",
      " |        input_signature: Input signature to be used instead of the one from file.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `(weights, state)` tuple.\n",
      " |  \n",
      " |  output_signature(self, input_signature)\n",
      " |      Returns output signature this layer would give for `input_signature`.\n",
      " |  \n",
      " |  pure_fn(self, x, weights, state, rng, use_cache=False)\n",
      " |      Applies this layer as a pure function with no optional args.\n",
      " |      \n",
      " |      This method exposes the layer's computation as a pure function. This is\n",
      " |      especially useful for JIT compilation. Do not override, use `forward`\n",
      " |      instead.\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Zero or more input tensors, packaged as described in the `Layer` class\n",
      " |            docstring.\n",
      " |        weights: A tuple or list of trainable weights, with one element for this\n",
      " |            layer if this layer has no sublayers, or one for each sublayer if\n",
      " |            this layer has sublayers. If a layer (or sublayer) has no trainable\n",
      " |            weights, the corresponding weights element is an empty tuple.\n",
      " |        state: Layer-specific non-parameter state that can update between batches.\n",
      " |        rng: Single-use random number generator (JAX PRNG key).\n",
      " |        use_cache: if `True`, cache weights and state in the layer object; used\n",
      " |          to implement layer sharing in combinators.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple of `(tensors, state)`. The tensors match the number (`n_out`)\n",
      " |        promised by this layer, and are packaged as described in the `Layer`\n",
      " |        class docstring.\n",
      " |  \n",
      " |  save_to_file(self, file_name, weights_only=False, input_signature=None)\n",
      " |      Saves this layer and its sublayers to a pickled checkpoint.\n",
      " |      \n",
      " |      Args:\n",
      " |        file_name: Name/path of the pickled weights/state file.\n",
      " |        weights_only: If `True`, save only the layer's weights. Else\n",
      " |            save both weights and state.\n",
      " |        input_signature: Input signature to be used.\n",
      " |  \n",
      " |  weights_and_state_signature(self, input_signature, unsafe=False)\n",
      " |      Return a pair containing the signatures of weights and state.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  has_backward\n",
      " |      Returns `True` if this layer provides its own custom backward pass code.\n",
      " |      \n",
      " |      A layer subclass that provides custom backward pass code (for custom\n",
      " |      gradients) must override this method to return `True`.\n",
      " |  \n",
      " |  n_in\n",
      " |      Returns how many tensors this layer expects as input.\n",
      " |  \n",
      " |  n_out\n",
      " |      Returns how many tensors this layer promises as output.\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this layer.\n",
      " |  \n",
      " |  sublayers\n",
      " |      Returns a tuple containing this layer's sublayers; may be empty.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  rng\n",
      " |      Returns this layer's current single-use random number generator.\n",
      " |      \n",
      " |      Code that wants to base random samples on this generator must explicitly\n",
      " |      split off new generators from it. (See, for example, the `rng` setter code\n",
      " |      below.)\n",
      " |  \n",
      " |  state\n",
      " |      Returns a tuple containing this layer's state; may be empty.\n",
      " |      \n",
      " |      If the layer has sublayers, the state by convention will be\n",
      " |      a tuple of length `len(sublayers)` containing sublayer states.\n",
      " |      Note that in this case self._state only marks which ones are shared.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns this layer's weights.\n",
      " |      \n",
      " |      Depending on the layer, the weights can be in the form of:\n",
      " |      \n",
      " |        - an empty tuple\n",
      " |        - a tensor (ndarray)\n",
      " |        - a nested structure of tuples and tensors\n",
      " |      \n",
      " |      If the layer has sublayers, the weights by convention will be\n",
      " |      a tuple of length `len(sublayers)` containing the weights of sublayers.\n",
      " |      Note that in this case self._weights only marks which ones are shared.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tl.Embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
